{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fdd5e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        R-Squared             MAE          MAPE    \n",
      "             mean std        mean std      mean std\n",
      "Degree                                             \n",
      "0       -0.011963 NaN   64.006461 NaN  0.627918 NaN\n",
      "1        0.452603 NaN   42.794095 NaN  0.374998 NaN\n",
      "2        0.415640 NaN   43.581693 NaN  0.382857 NaN\n",
      "3      -15.501646 NaN  178.067416 NaN  1.614539 NaN\n",
      "4      -26.728083 NaN  261.667144 NaN  2.300991 NaN\n",
      "5      -25.992920 NaN  255.968358 NaN  2.270202 NaN\n",
      "6      -25.975743 NaN  255.908618 NaN  2.269658 NaN\n",
      "7      -25.975478 NaN  255.906822 NaN  2.269649 NaN\n",
      "8      -25.975555 NaN  255.907099 NaN  2.269653 NaN\n"
     ]
    }
   ],
   "source": [
    "#Loading the required libraries\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Loading the diabetes dataset fromsklearn_datasets\n",
    "diabetes_df = load_diabetes()\n",
    "X, y = diabetes_df.data, diabetes_df.target\n",
    "\n",
    "# Splitting the data into training and testing sets i.e. test_size as 20% and train_size as 80%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Performing cross-validation on polynomial models\n",
    "# Here, we want to perform cross-validation on nine polynomial models from degree 0 to 8 so using range function which will take values from 0 to 8\n",
    "degrees = range(9) \n",
    "results = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    r2 = r2_score(y_test, y_pred) #Calculating r2 score\n",
    "    mae = mean_absolute_error(y_test, y_pred) #Calculating mean absolute error score\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred) #Calculating mean absolute percentage error score\n",
    "    \n",
    "    results.append((degree, r2, mae, mape))\n",
    "\n",
    "# Constructing a DataFrame to store the results\n",
    "results_df = pd.DataFrame(results, columns=['Degree', 'R-Squared', 'MAE', 'MAPE'])\n",
    "\n",
    "# Calculating mean and standard deviation\n",
    "mean_std_df = results_df.groupby('Degree').agg({\n",
    "    'R-Squared': ['mean', 'std'],\n",
    "    'MAE': ['mean', 'std'],\n",
    "    'MAPE': ['mean', 'std']\n",
    "})\n",
    "\n",
    "# Displaying the summary table\n",
    "print(mean_std_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488af3ea",
   "metadata": {},
   "source": [
    "It seems that for each degree, the standard deviation (std) is showing as NaN. This suggests that for each degree, there is only one data point available for evaluation.\n",
    "\n",
    "This could be due to the specific characteristics of the dataset or how the data is being split in the cross-validation process. For certain degrees, the data may be too sparse or there might be some other issue causing this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f98f3",
   "metadata": {},
   "source": [
    "3. Identification of the Best Model: Identify the model that exhibits the highest performance based on the R-Squared, MAE and MAPE metrics. Provide an explanation for choosing this specific model.\n",
    "\n",
    "\n",
    "* Based on the mean R-Squared, MAE, and MAPE metrics, it appears that the model with degree 1 (quadratic polynomial) has the highest R-Squared (0.45) and the lowest MAE (42.79) and MAPE (0.37). This suggests that the quadratic polynomial model performs the best among the tested degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e11f8",
   "metadata": {},
   "source": [
    "Explanation for Choosing the Specific Model (Degree 1):\n",
    "\n",
    "R-Squared: The model with degree 1 has the highest R-squared value, indicating that it explains a significant portion of the variance in the data. This suggests that the quadratic model fits the data well.\n",
    "\n",
    "MAE and MAPE: The model with degree 1 also has the lowest Mean Absolute Error (MAE) and Mean Absolute Percentage Error (MAPE). This indicates that it has the smallest average absolute difference between predicted and actual values, which is desirable for predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa412b37",
   "metadata": {},
   "source": [
    "4. Additional analysis and interpretation of the models' performances. You may explore further insights beyond the required metrics. The analysis should provide at least one relevant insight about the choice of the best model, or about characteristics of the chosen one (for example - an analysis of in which instances does it fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a15ddbf",
   "metadata": {},
   "source": [
    "It's important to note that for higher degree models (e.g., degrees 3 to 8), the R-Squared values are significantly negative. This indicates that these models are performing very poorly and may be overfitting to the training data. This is likely due to the models becoming too complex and capturing noise in the data.\n",
    "\n",
    "Based on this, it's recommended to use the quadratic model (degree 1) for making predictions, as it strikes a good balance between model complexity and predictive performance. However, it's crucial to also consider other factors like interpretability and computational resources when choosing a final model. Further analysis and potentially trying more advanced techniques like regularized regression could also be beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad3848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
